---
title: 代码解读：Event-based Stereo Visual Odometry
author: 2c984r83y
date: 2023-10-17 23:33:33 +0800
categories: [TecDoc, Code Understanding]
tags: [Cpp, Event-based Vision, ESVO]
pin: false
math: true
mermaid: true
---
[Event-based Stereo Visual Odometry](https://doi.org/10.1109/TRO.2021.3062252) 提出了一种基于双目事件相机的视觉里程计。在 [Github上开源了代码](https://github.com/HKUST-Aerial-Robotics/ESVO.git)，项目主要由 Cpp 实现，运行环境为 ROS, 本文的重点并不是如何运行代码，所以忽略了 ROS 中节点以及 launch file.  ~~TODO: 挖个坑以后填上~~，本文旨在对其中的功能实现的部分关键代码进行解读。

本文之后的部分将 Event-based Stereo Visual Odometry 简写为ESVO.

## ESVO System Flowchart

ESVO 的 flowchat 如下图所示，主要由三大部分组成，分别是 Event Preprocessing, Mapping, Tracking.

* Event Preprocessing
  对输入的原始事件流进行滤波，生成 Time-Surface Maps.
* Mapping
  接收Time-Surface, 进行双目匹配，得到深度，生成 Local Map 与 Point Cloud.
* Tracking
  对 Local Map 进行跟踪，生成相机的 Pose(6Dof), 将变换矩阵返回给 Mapping 模块

![20231019162018](https://raw.githubusercontent.com/2c984r83y/2c984r83y.github.io/master/images/20231019162018.png)
_ESVO System Flowchart[^1]_

## ESVO 代码组成

> 本文图片若无特殊说明均来自于 `Scientific Toolworks Understand v6.4`
{: .prompt-info }

ESVO 代码组成如下图所示，主要由三个模块组成，分别是 `esvo_time_surface`, `esvo_Mapping`, `esvo_Tracking`.  

TimeSurface
: `esvo_time_surface` 中的 `TimeSurface` 实现了 Event Preprocessing 部分，对输入的原始事件流进行滤波，生成 Time-Surface Maps.  

esvo_Mapping
: `esvo_core` 中的 `esvo_Mapping` 实现了 Mapping 部分，接收Time-Surface，得到深度，生成 Local Map 与 Point Cloud.  

esvo_Tracking
: `esvo_core` 中的 `esvo_Tracking` 实现了 Tracking 部分，对 Local Map 进行跟踪，生成相机的 Pose(6Dof), 将变换矩阵返回给 Mapping 模块  

esvo_MVStereo
: `esvo_core` 中的 `esvo_MVStereo` 实现了 ESVO mapper 部分，以及其他的一些 event-based mapping methods[^2], [^3]. 作为 multi-view stereo (MVS) pipeline, 该模块需要先验的 pose 作为输入

![MetricsTreemap-CountLine-MaxCyclomatic](https://raw.githubusercontent.com/2c984r83y/2c984r83y.github.io/master/images/MetricsTreemap-CountLine-MaxCyclomatic.png)

### TimeSurface

> TODO
{: .prompt-info }

### Mapping

Mapping 部分代码在 `esvo_core` 中实现， Mapping 的主要功能是接收 Time-Surface, 进行双目匹配，得到深度。  
ESVO 创新性地提出了一种基于非线性优化衡量事件流时空一致性的目标函数的 mapping 方法。
A novel mapping method based on the optimization of an objective function designed to measure spatio-temporal consistency across stereo event streams.
非线性优化目标函数的十七最小的过程需要初值，ESVO 采用了 ZNCC 块匹配 Block Match 的方法，相较于暴力搜索 Bruteforce Search 更高效。
关于 ZNCC 的原理，本博客在之前已经做了详细的说明，你可以点击这里查看：[ZNCC](https://2c984r83y.github.io/posts/NCC_ZNCC/ "ZNCC")
> ZNCC 是否影响了 ESVO 的初始化效果？
{: .prompt-tip }
#### CreatMatchProblem

> TODO： CreatMatchProblem
{: .prompt-info }

#### Block Match

Block Match 采用 ZNCC 的方法，为了提高计算效率，达到实时性的要求，ESVO 采用了多线程的方法，将计算任务分配给多个线程，同时进行计算。关于 Cpp 多线程的操作有待深入学习，本文不做过多的解读。

> TODO: Cpp Multithreading
{: .prompt-info }

初始化部分求左右目的视差值的代码是在 `esvo_core\src\core\EventBM.cpp` 中实现，`EventBM.cpp` 被 `esvo_MVStereo.cpp` 和 `esvo_Mapping.cpp` 调用。

`Event_BM.cpp` 的 Data Flow Out & Data Flow In 如下图所示：

`esvo_Mapping::MappingAtTime(const ros::Time& t)` 调用了 `esvo_core\src\core\EventBM.cpp` 中的 `esvo_core::core::EventBM::createMatchProblem` 和 `esvo_core::core::EventBM::match_all_HyperThread`

```cpp
  // block matching
  tt_mapping.tic();
  ebm_.createMatchProblem(&TS_obs_, &st_map_, &vDenoisedEventsPtr_left_);
  ebm_.match_all_HyperThread(vEMP);
```

被调用的两个函数的声明如下 `esvo_core\include\esvo_core\core\EventBM.h`：

```cpp
  void createMatchProblem(
    StampedTimeSurfaceObs * pStampedTsObs,
    StampTransformationMap * pSt_map,
    std::vector<dvs_msgs::Event *>* pvEventsPtr);
```

```cpp
void match_all_HyperThread(std::vector<EventMatchPair> &vEMP);
```

`match_all_HyperThread` 调用了 `void esvo_core::core::EventBM::match(EventBM::Job& job)`
![20231020111608](https://raw.githubusercontent.com/2c984r83y/2c984r83y.github.io/master/images/20231020111608.png)

`match` 函数调用了 `bool esvo_core::core::EventBM::match_an_event(*ev_it, pDisparityBound, emp)`

`match_an_event` 函数实现了双目匹配的核心算法，调用了 `bool esvo_core::core::EventBM::epipolarSearching`
`epipolarSearching` 计算 ZNCC 的 cost

![20231020111747](https://raw.githubusercontent.com/2c984r83y/2c984r83y.github.io/master/images/20231020111747.png)

#### Problem Solver

> TODO: Problem Solver
{: .prompt-info }


### Tracking

> TODO: Tracking
{: .prompt-info }

## Reference

[^1]: ZHOU Y, GALLEGO G, SHEN S. “Event-based Stereo Visual Odometry,” IEEE Transactions on Robotics, 37(5): 1433-1450, 2021. DOI:[10.1109/TRO.2021.3062252](https://doi.org/10.1109/TRO.2021.3062252).
[^2]: S.-H. Ieng, J. Carneiro, M. Osswald, and R. Benosman, “Neuromorphic event-based generalized time-based stereovision,” Front. Neurosci., vol. 12, p. 442, 2018.  
[^3]: H. Hirschmuller, “Stereo processing by semiglobal matching and mutual information,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 2, pp. 328–341, Feb. 2008.
