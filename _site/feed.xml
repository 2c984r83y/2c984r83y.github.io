

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://2c984r83y.github.io/</id>
  <title>2c984r83y</title>
  <subtitle>A blog under construction</subtitle>
  <updated>2023-10-27T16:19:20+08:00</updated>
  <author>
    <name>2c984r83y</name>
    <uri>https://2c984r83y.github.io/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="https://2c984r83y.github.io/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="zh-CN"
    href="https://2c984r83y.github.io/"/>
  <generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator>
  <rights> © 2023 2c984r83y </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>代码解读：Event-based Stereo Visual Odometry</title>
    <link href="https://2c984r83y.github.io/posts/ESVO/" rel="alternate" type="text/html" title="代码解读：Event-based Stereo Visual Odometry" />
    <published>2023-10-17T23:33:33+08:00</published>
  
    <updated>2023-10-27T12:48:27+08:00</updated>
  
    <id>https://2c984r83y.github.io/posts/ESVO/</id>
    <content src="https://2c984r83y.github.io/posts/ESVO/" />
    <author>
      <name>2c984r83y</name>
    </author>

  
    
    <category term="TecDoc" />
    
    <category term="Code Understanding" />
    
  

  
    <summary>
      





      Event-based Stereo Visual Odometry 提出了一种基于双目事件相机的视觉里程计。
在 Github上开源了代码，项目主要由 Cpp 实现，运行环境为 ROS, 本文的重点并不是如何运行代码，所以忽略了 ROS 中节点以及 launch file.  挖个坑以后填上，本文旨在对其中的功能实现的部分关键代码进行解读。

本文之后的部分将 Event-based Stereo Visual Odometry 简写为ESVO.
为了提高计算效率，达到实时性的要求，ESVO 采用了多线程的方法，将计算任务分配给多个线程，同时进行计算。Cpp 多线程的操作有待深入学习。现在看不懂


  TODO: Cpp Multithreading


System Flowchart

ESVO 的 flowchat 如下图所示，主要由三大部分组成，分别是 Event Pre...
    </summary>
  

  </entry>

  
  <entry>
    <title>事件相机图像重构：浅谈Time-Surface</title>
    <link href="https://2c984r83y.github.io/posts/timesurface/" rel="alternate" type="text/html" title="事件相机图像重构：浅谈Time-Surface" />
    <published>2023-10-12T23:33:33+08:00</published>
  
    <updated>2023-10-20T17:34:54+08:00</updated>
  
    <id>https://2c984r83y.github.io/posts/timesurface/</id>
    <content src="https://2c984r83y.github.io/posts/timesurface/" />
    <author>
      <name>2c984r83y</name>
    </author>

  
    
    <category term="TecDoc" />
    
    <category term="Paper Reading" />
    
  

  
    <summary>
      





      事件相机简介

事件相机只输出亮度变化超过一定阈值的像素坐标、时间戳与极性。因为事件流是异步产生的，与传统的固定事件曝光的图像相比富含更时空信息，所以将事件流转换为图像帧的算法至关重要，选对了算法就能发挥事件相机的高时间分辨率优势。事件相机与传统的高速相机相比，输出的事件流中不含冗余的背景图像信息，事件流只输出亮度变化超过阈值的运动物体的信息，这是我们感兴趣的，因此提高了处理速度，降低了数据量，避免使用过多的硬件资源，更利于实时计算。

事件相机的一般输出形式是事件流，事件流可以表示成如下的形式：

$ev_i=[\mathbf{x_i},t_i,p_i]^T,\quad i\in\mathbb{N},$

$ev_i$是第i个事件，其坐标为$\mathbf{x_i}=[x_i,y_i]^T$

时间戳$t_i$，极性$ p_{i}\in{-1,1}$，-1表示OFF事件，1表示ON...
    </summary>
  

  </entry>

  
  <entry>
    <title>Prophesee Mono Calibration</title>
    <link href="https://2c984r83y.github.io/posts/mono_calibration/" rel="alternate" type="text/html" title="Prophesee Mono Calibration" />
    <published>2023-09-19T23:33:33+08:00</published>
  
    <updated>2023-10-20T17:34:54+08:00</updated>
  
    <id>https://2c984r83y.github.io/posts/mono_calibration/</id>
    <content src="https://2c984r83y.github.io/posts/mono_calibration/" />
    <author>
      <name>2c984r83y</name>
    </author>

  
    
    <category term="TecDoc" />
    
  

  
    <summary>
      





      Intrinsics Calibration



建立相机成像几何模型并矫正透镜畸变。

使用基于事件的2D角点检测对相机进行标定。


  首先对闪烁棋牌格进行检测：


代码路径如下所示：


  &amp;lt;install-prefix&amp;gt;/share/metavision/sdk/calibration/apps/metavision_mono_calibration_recording



  使用检测数据进行相机内参计算：


代码路径如下所示：


  &amp;lt;install-prefix&amp;gt;/share/metavision/sdk/calibration/apps/metavision_mono_calibration


闪烁棋盘格与标定界面



代码流水线结构



Trail Stage

使用 Metavision::TrailFilterAlgo...
    </summary>
  

  </entry>

  
  <entry>
    <title>详解零均值归一化：ZNCC</title>
    <link href="https://2c984r83y.github.io/posts/NCC_ZNCC/" rel="alternate" type="text/html" title="详解零均值归一化：ZNCC" />
    <published>2023-09-12T23:33:33+08:00</published>
  
    <updated>2023-10-20T17:34:54+08:00</updated>
  
    <id>https://2c984r83y.github.io/posts/NCC_ZNCC/</id>
    <content src="https://2c984r83y.github.io/posts/NCC_ZNCC/" />
    <author>
      <name>2c984r83y</name>
    </author>

  
    
    <category term="TecDoc" />
    
  

  
    <summary>
      





      零均值归一化：ZNCC, 是一种进行双目深度估计的算法，主要思想为匹配左右目零均值归一化系数最小的两点。

立体匹配与深度计算

非基于深度学习的双目匹配算法大致分为四步：


  采集图像
  极线矫正
  特征匹配
  深度恢复


NCC 与 ZNCC 是衡量特征匹配的算法，一般采用 WTA 的方法得到视差。

双目视觉的几何原理并不是本文的重点，挖个坑以后再填

标准差、方差、协方差、相关系数

标准差

标准差描述了变量在整体变化过程中偏离均值的幅度。

\[\sigma = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(X_i-\overline{X})^{2}}\]

标准差越小，说明数据越集中。

所以在协方差中标准差作为分母对协方差进行了归一化。

方差

标准差的平方，衡量离散程度，计算每一个变量（观察值）与总体均数之间的差异。

\[Var(X...
    </summary>
  

  </entry>

  
  <entry>
    <title>RPG_EMVS</title>
    <link href="https://2c984r83y.github.io/posts/rpg_emvs/" rel="alternate" type="text/html" title="RPG_EMVS" />
    <published>2023-09-11T23:33:33+08:00</published>
  
    <updated>2023-10-20T17:34:54+08:00</updated>
  
    <id>https://2c984r83y.github.io/posts/rpg_emvs/</id>
    <content src="https://2c984r83y.github.io/posts/rpg_emvs/" />
    <author>
      <name>2c984r83y</name>
    </author>

  
    
    <category term="TecDoc" />
    
  

  
    <summary>
      





      Introduction

RPG_EMVS is the implementation of EMVS: Event-based Multi-View Stereo.

You can find it here.

Installation

Clone the responsity

cd home\yousa\rosCatkinBuild\src


git clone git@github.com:uzh-rpg/rpg_emvs.git


Run sample

cd home\yousa\rosCatkinBuild\src\ros_emvc
mkdir sample &amp;amp;&amp;amp; cd sample
source /home/yousa/rosCatkinBuild/devel/setup.zsh
rosrun mapper_emvs run_emvs --b...
    </summary>
  

  </entry>

</feed>


